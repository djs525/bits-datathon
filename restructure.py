#!/usr/bin/env python3
"""
restructure.py
==============
Reorganizes the bits-datathon project into a clean frontend/backend layout.

Run from the project root:
    python restructure.py

    # Dry run first (see what will happen without moving anything):
    python restructure.py --dry-run

Final structure
---------------
restaurant-gap/
├── backend/
│   ├── main.py                     ← FastAPI app (updated with /predict)
│   ├── generate_gap_analysis.py    ← Generates data/gap_analysis.json
│   ├── compute_review_features.py  ← Extracts review features
│   ├── train_survival_model.py     ← Trains XGBoost survival model
│   ├── requirements.txt
│   └── Dockerfile
│
├── frontend/
│   ├── public/
│   ├── src/
│   │   ├── App.js
│   │   ├── api.js
│   │   ├── components/
│   │   │   └── ui.js
│   │   └── pages/
│   │       ├── Opportunities.js
│   │       ├── Search.js
│   │       └── Weakspots.js
│   ├── package.json
│   └── Dockerfile
│
├── data/
│   ├── gap_analysis.json           ← generated by generate_gap_analysis.py
│   ├── yelp_nj_restaurants.json
│   └── yelp_nj_reviews.json
│
├── models/
│   ├── survival_model.json
│   ├── feature_importance.json
│   └── model_metadata.json
│
└── docker-compose.yml
"""

import argparse
import os
import shutil
import sys
from pathlib import Path


# ── Move plan ─────────────────────────────────────────────────────────────────
# Each entry: (glob_or_name, destination_relative_to_root)
# Globs are matched against the current directory.

MOVE_PLAN = [
    # ── Backend Python files ──────────────────────────────────────────────────
    ("main.py",                         "backend/main.py"),
    ("generate_gap_analysis.py",        "backend/generate_gap_analysis.py"),
    ("compute_review_features.py",      "backend/compute_review_features.py"),
    ("train_survival_model.py",         "backend/train_survival_model.py"),
    ("extract_nj_reviews.py",           "backend/extract_nj_reviews.py"),
    ("filter_nj_restaurants.py",        "backend/filter_nj_restaurants.py"),
    ("tree.py",                         "backend/tree.py"),
    ("requirements.txt",                "backend/requirements.txt"),

    # ── Frontend React files ──────────────────────────────────────────────────
    ("App.js",                          "frontend/src/App.js"),
    ("Opportunities.js",                "frontend/src/pages/Opportunities.js"),
    ("Search.js",                       "frontend/src/pages/Search.js"),
    ("Weakspots.js",                    "frontend/src/pages/Weakspots.js"),

    # ── Data files ────────────────────────────────────────────────────────────
    ("gap_analysis.json",               "data/gap_analysis.json"),
    ("yelp_nj_restaurants.json",        "data/yelp_nj_restaurants.json"),
    ("yelp_nj_reviews.json",            "data/yelp_nj_reviews.json"),
    ("yelp_nj_business.json",           "data/yelp_nj_business.json"),
    ("yelp_nj_restaurants.csv",         "data/yelp_nj_restaurants.csv"),
    ("yelp_nj_restaurants_by_zip.csv",  "data/yelp_nj_restaurants_by_zip.csv"),
    ("review_features.json",            "data/review_features.json"),

    # ── Models ────────────────────────────────────────────────────────────────
    ("models/survival_model.json",      "models/survival_model.json"),
    ("models/feature_importance.json",  "models/feature_importance.json"),
    ("models/model_metadata.json",      "models/model_metadata.json"),
]

# Files/dirs to skip entirely (temp files, duplicates, IDE files)
SKIP_NAMES = {
    "__pycache__", ".DS_Store", "*.pyc",
    "yelp_academic_dataset_business.json",  # too large, keep in place
    "yelp_academic_dataset_review.json",    # too large, keep in place
    "yelp_nj_reviews copy.json",            # duplicate
    "yelp_nj_reviews copy.json.zip",        # duplicate
}


# ── Dockerfile templates ──────────────────────────────────────────────────────

BACKEND_DOCKERFILE = """\
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
"""

FRONTEND_DOCKERFILE = """\
FROM node:20-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=build /app/build /usr/share/nginx/html
EXPOSE 3000
CMD ["nginx", "-g", "daemon off;"]
"""

DOCKER_COMPOSE = """\
version: "3.9"

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/../data:ro
      - ./models:/app/../models:ro
    environment:
      - PYTHONUNBUFFERED=1

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
    environment:
      - REACT_APP_API_URL=http://localhost:8000
"""

REQUIREMENTS_TXT = """\
fastapi>=0.110.0
uvicorn[standard]>=0.29.0
pydantic>=2.0.0
xgboost>=2.0.0
scikit-learn>=1.4.0
pandas>=2.0.0
numpy>=1.26.0
vaderSentiment>=3.3.2
tqdm>=4.66.0
shap>=0.44.0
"""

API_JS = """\
// src/api.js  — all backend API calls in one place
const BASE = process.env.REACT_APP_API_URL || "http://localhost:8000";

async function get(path, params = {}) {
  const qs = new URLSearchParams(
    Object.fromEntries(Object.entries(params).filter(([, v]) => v !== undefined && v !== null && v !== ""))
  ).toString();
  const url = `${BASE}${path}${qs ? "?" + qs : ""}`;
  const res = await fetch(url);
  if (!res.ok) throw new Error(`API error ${res.status}: ${await res.text()}`);
  return res.json();
}

async function post(path, body) {
  const res = await fetch(`${BASE}${path}`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(body),
  });
  if (!res.ok) throw new Error(`API error ${res.status}: ${await res.text()}`);
  return res.json();
}

export const api = {
  getCuisines:     ()       => get("/meta/cuisines"),
  getModelInfo:    ()       => get("/meta/model"),
  getOpportunities:(params) => get("/opportunities", params),
  getOpportunity:  (zip)    => get(`/opportunity/${zip}`),
  search:          (params) => get("/search", params),
  getWeakspots:    (params) => get("/weakspots", params),
  predict:         (body)   => post("/predict", body),
};
"""


# ── Helpers ───────────────────────────────────────────────────────────────────

GREEN  = "\033[92m"
YELLOW = "\033[93m"
BLUE   = "\033[94m"
RED    = "\033[91m"
RESET  = "\033[0m"
BOLD   = "\033[1m"

def log(msg, color=RESET):     print(f"{color}{msg}{RESET}")
def ok(msg):                   log(f"  ✓  {msg}", GREEN)
def skip(msg):                 log(f"  –  {msg}", YELLOW)
def warn(msg):                 log(f"  ⚠  {msg}", RED)
def header(msg):               log(f"\n{BOLD}{msg}{RESET}")


def write_file(path: Path, content: str, dry_run: bool):
    """Write a text file, creating parent dirs as needed."""
    if dry_run:
        skip(f"[dry-run] Would write: {path}")
        return
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")
    ok(f"Created: {path}")


def move_file(src: Path, dst: Path, dry_run: bool):
    """Move src → dst, creating parent dirs. Skip if src doesn't exist."""
    if not src.exists():
        skip(f"Not found (skip): {src.name}")
        return
    if dry_run:
        skip(f"[dry-run] {src}  →  {dst}")
        return
    dst.parent.mkdir(parents=True, exist_ok=True)
    shutil.move(str(src), str(dst))
    ok(f"{src.name}  →  {dst}")


# ── Main ──────────────────────────────────────────────────────────────────────

def main():
    parser = argparse.ArgumentParser(description="Restructure the bits-datathon project.")
    parser.add_argument("--dry-run", action="store_true", help="Preview changes without moving files")
    parser.add_argument("--root", default=".", help="Project root directory (default: current dir)")
    args = parser.parse_args()

    root = Path(args.root).resolve()
    dry = args.dry_run

    if dry:
        log(f"\n{BOLD}{'='*60}", BLUE)
        log(f"  DRY RUN — no files will be moved", BLUE)
        log(f"{'='*60}{RESET}", BLUE)

    log(f"\n{BOLD}Project root: {root}{RESET}")

    # ── Step 1: Move files ────────────────────────────────────────────────────
    header("Step 1: Moving files")
    for src_rel, dst_rel in MOVE_PLAN:
        src = root / src_rel
        dst = root / dst_rel
        if src == dst:
            skip(f"Already in place: {dst_rel}")
            continue
        move_file(src, dst, dry)

    # ── Step 2: Write scaffold files ─────────────────────────────────────────
    header("Step 2: Writing scaffold files")

    write_file(root / "backend" / "Dockerfile",         BACKEND_DOCKERFILE, dry)
    write_file(root / "frontend" / "Dockerfile",        FRONTEND_DOCKERFILE, dry)
    write_file(root / "docker-compose.yml",             DOCKER_COMPOSE, dry)
    write_file(root / "backend" / "requirements.txt",   REQUIREMENTS_TXT, dry)
    write_file(root / "frontend" / "src" / "api.js",    API_JS, dry)

    # ── Step 3: Create empty placeholder dirs ─────────────────────────────────
    header("Step 3: Creating directory structure")
    placeholder_dirs = [
        "frontend/public",
        "frontend/src/components",
        "frontend/src/hooks",
        "data",
        "models",
    ]
    for d in placeholder_dirs:
        full = root / d
        if dry:
            skip(f"[dry-run] mkdir: {d}")
        else:
            full.mkdir(parents=True, exist_ok=True)
            ok(f"mkdir: {d}")

    # ── Step 4: Print final tree ──────────────────────────────────────────────
    header("Final structure")
    tree_lines = [
        "restaurant-gap/",
        "├── backend/",
        "│   ├── main.py                     ← FastAPI (with /predict endpoint)",
        "│   ├── generate_gap_analysis.py    ← Run this FIRST to create gap_analysis.json",
        "│   ├── compute_review_features.py",
        "│   ├── train_survival_model.py",
        "│   ├── requirements.txt",
        "│   └── Dockerfile",
        "├── frontend/",
        "│   └── src/",
        "│       ├── App.js",
        "│       ├── api.js                  ← includes /predict call",
        "│       ├── components/",
        "│       └── pages/",
        "│           ├── Opportunities.js",
        "│           ├── Search.js",
        "│           └── Weakspots.js",
        "├── data/",
        "│   ├── gap_analysis.json           ← generated",
        "│   ├── yelp_nj_restaurants.json",
        "│   └── yelp_nj_reviews.json",
        "├── models/",
        "│   ├── survival_model.json",
        "│   ├── feature_importance.json",
        "│   └── model_metadata.json",
        "└── docker-compose.yml",
    ]
    for line in tree_lines:
        log(f"  {line}", BLUE)

    # ── Step 5: Print next steps ───────────────────────────────────────────────
    header("Next steps")
    steps = [
        ("1", "Generate gap_analysis.json (required for the API to start):",
              "python backend/generate_gap_analysis.py"),
        ("2", "Compute review features (if not done):",
              "python backend/compute_review_features.py"),
        ("3", "Train the survival model:",
              "python backend/train_survival_model.py"),
        ("4", "Start everything with Docker:",
              "docker-compose up --build"),
        ("5", "Or run the backend manually:",
              "cd backend && uvicorn main:app --reload"),
        ("6", "Test the predict endpoint:",
              'curl -X POST http://localhost:8000/predict \\\n'
              '  -H "Content-Type: application/json" \\\n'
              '  -d \'{"zip_code":"08053","cuisine":"Japanese","price_tier":2,"has_delivery":1}\''),
    ]
    for num, desc, cmd in steps:
        log(f"\n  {BOLD}{num}. {desc}{RESET}")
        log(f"     {GREEN}{cmd}{RESET}")

    if dry:
        log(f"\n{YELLOW}  Dry run complete. Re-run without --dry-run to apply.{RESET}")
    else:
        log(f"\n{GREEN}{BOLD}  ✓ Restructure complete!{RESET}")


if __name__ == "__main__":
    main()